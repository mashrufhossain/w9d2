# Model Serving API (FastAPI + Batch + Docker + Prometheus)

This project implements a minimal production-style ML inference system with:

- REST API (FastAPI)
- Prediction endpoint
- Prometheus metrics
- Batch inference script
- Docker image

---

## ðŸš€ Setup Instructions

### Install dependencies
